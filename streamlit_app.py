import streamlit as st
import pandas as pd
import pydeck as pdk
from snowflake.snowpark.context import get_active_session

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(layout="wide", page_title="å†é…ç½®ãƒ‡ãƒ¼ã‚¿é«˜åº¦åˆ†æ")

st.title("ğŸ” å†é…ç½®ãƒ‡ãƒ¼ã‚¿ é«˜åº¦ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ï¼†åˆ†æ")

# ---------------------------------------------------------
# ç®¡ç†è€…è¨­å®š: Git API Integration
# ---------------------------------------------------------
with st.expander("âš™ï¸ ç®¡ç†è€…è¨­å®š: Git API Integration", expanded=False):
    st.markdown("### Git API Integrationã®ä½œæˆ")
    st.info("GitHubãƒªãƒã‚¸ãƒˆãƒªã¨Snowflakeã‚’é€£æºã™ã‚‹ãŸã‚ã®API Integrationã‚’ä½œæˆã—ã¾ã™ã€‚\n"
            "â€»ã“ã®æ“ä½œã«ã¯ACCOUNTADMINãƒ­ãƒ¼ãƒ«ã¾ãŸã¯CREATE INTEGRATIONæ¨©é™ãŒå¿…è¦ã§ã™ã€‚")
    
    if st.button("ğŸ”— Git API Integration ã‚’ä½œæˆ", type="primary"):
        try:
            session = get_active_session()
            sql = """
            CREATE OR REPLACE API INTEGRATION git_api_integration
              API_PROVIDER = git_https_api
              API_ALLOWED_PREFIXES = ('https://github.com/ha-se')
              ENABLED = TRUE;
            """
            session.sql(sql).collect()
            st.success("âœ… API Integration 'git_api_integration' ã®ä½œæˆã«æˆåŠŸã—ã¾ã—ãŸï¼")
        except Exception as e:
            st.error(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
    
    st.markdown("---")

# ---------------------------------------------------------
# 1. ãƒ‡ãƒ¼ã‚¿å–å¾—é–¢æ•°ï¼ˆãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿ ï¼† ãƒã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ï¼‰
# ---------------------------------------------------------
@st.cache_data
def load_all_data():
    session = get_active_session()
    
    # (1) ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿ã®å–å¾—
    df_main = session.table("DEMO_DB.SALES_SCHEMA.REALLOCATION_DATA").to_pandas()
    
    # (2) é™¤å¤–ç”¨ãƒã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ã®å–å¾—
    try:
        df_master = session.table("DEMO_DB.SALES_SCHEMA.REALLOCATION_MASTER").to_pandas()
    except:
        df_master = pd.DataFrame() # ãƒ†ãƒ¼ãƒ–ãƒ«ãŒãªã„å ´åˆã®ä¿é™º
    
    # --- ãƒ‡ãƒ¼ã‚¿å‹å¤‰æ›ï¼ˆãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿ï¼‰ ---
    # æ—¥ä»˜
    df_main["ä½œæˆæ—¥æ™‚"] = pd.to_datetime(df_main["ä½œæˆæ—¥æ™‚"], errors='coerce')
    
    # æ•°å€¤ï¼ˆè·é›¢ãƒ»IDãªã©ï¼‰
    df_main["å†é…ç½®è·é›¢(km)"] = pd.to_numeric(df_main["å†é…ç½®è·é›¢(km)"], errors='coerce')
    df_main["Start Port Id"] = pd.to_numeric(df_main["Start Port Id"], errors='coerce')
    df_main["Return Port Id"] = pd.to_numeric(df_main["Return Port Id"], errors='coerce')

    # åœ°å›³ç”¨ï¼ˆç·¯åº¦çµŒåº¦ï¼‰
    df_main = df_main.rename(columns={"ç·¯åº¦_å†é…ç½®å…ˆ": "lat", "çµŒåº¦_å†é…ç½®å…ˆ": "lon"})
    df_main["lat"] = pd.to_numeric(df_main["lat"], errors='coerce')
    df_main["lon"] = pd.to_numeric(df_main["lon"], errors='coerce')
    
    # --- ãƒ‡ãƒ¼ã‚¿å‹å¤‰æ›ï¼ˆãƒã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ï¼‰ ---
    if not df_master.empty and 'ST_ID' in df_master.columns:
        exclude_ids = df_master['ST_ID'].dropna().astype(int).tolist()
    else:
        exclude_ids = []

    # ========================================================
    # â˜…è¿½åŠ æ©Ÿèƒ½: ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ç”¨ã®ã€Œå¸‚åŒºç”ºæ‘+è¡Œæ”¿åŒºã€åˆ—ã‚’ä½œæˆ
    # ========================================================
    # (A) å›åå…ƒ
    if "å›åå…ƒ_å¸‚åŒºç”ºæ‘+è¡Œæ”¿åŒº" in df_main.columns:
        if "å›åå…ƒ_å¸‚åŒºç”ºæ‘+è¡Œæ”¿åŒº" in df_main.columns:
            # 2ã¤ã®åˆ—ã‚’çµåˆï¼ˆä¾‹: æ¨ªæµœå¸‚ + ä¸­åŒº = æ¨ªæµœå¸‚ä¸­åŒºï¼‰â€»æ¬ æå€¤ã¯ç©ºæ–‡å­—æ‰±ã„
            df_main["_filter_å›åå…ƒ_è©³ç´°"] = df_main["å›åå…ƒ_å¸‚åŒºç”ºæ‘+è¡Œæ”¿åŒº"].fillna("") + df_main["å›åå…ƒ_å¸‚åŒºç”ºæ‘+è¡Œæ”¿åŒº"].fillna("")
        else:
            df_main["_filter_å›åå…ƒ_è©³ç´°"] = df_main["å›åå…ƒ_å¸‚åŒºç”ºæ‘+è¡Œæ”¿åŒº"]
    
    # (B) å†é…ç½®å…ˆ
    if "å†é…ç½®å…ˆ_å¸‚åŒºç”ºæ‘+è¡Œæ”¿åŒº" in df_main.columns:
        if "å†é…ç½®å…ˆ_å¸‚åŒºç”ºæ‘+è¡Œæ”¿åŒº" in df_main.columns:
            df_main["_filter_å†é…ç½®å…ˆ_è©³ç´°"] = df_main["å†é…ç½®å…ˆ_å¸‚åŒºç”ºæ‘+è¡Œæ”¿åŒº"].fillna("") + df_main["å†é…ç½®å…ˆ_å¸‚åŒºç”ºæ‘+è¡Œæ”¿åŒº"].fillna("")
        else:
            df_main["_filter_å†é…ç½®å…ˆ_è©³ç´°"] = df_main["å†é…ç½®å…ˆ_å¸‚åŒºç”ºæ‘+è¡Œæ”¿åŒº"]

    return df_main, exclude_ids

# ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿å®Ÿè¡Œ
raw_df, exclude_ids = load_all_data()


# ---------------------------------------------------------
# 2. ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°å‡¦ç†ï¼ˆè‡ªå‹•ã‚¹ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ï¼‰
# ---------------------------------------------------------
st.sidebar.header("ğŸ§¹ è‡ªå‹•ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°è¨­å®š")
apply_cleaning = st.sidebar.checkbox("ãƒã‚¹ã‚¿æ¡ä»¶ã§é™¤å¤–å‡¦ç†ã‚’è¡Œã†", value=True)

# ---------------------------------------------------------
# 2.5 è‰²åˆ†ã‘ç”¨CSVèª­ã¿è¾¼ã¿
# ---------------------------------------------------------
st.sidebar.markdown("---")
st.sidebar.header("ğŸ¨ åœ°å›³è‰²åˆ†ã‘è¨­å®š")
st.sidebar.caption("collection.csvã¨allocation.csvã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã¨ã€è©²å½“ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’é’è‰²ã§è¡¨ç¤ºã—ã¾ã™")

collection_file = st.sidebar.file_uploader("collection.csv", type=['csv'])
allocation_file = st.sidebar.file_uploader("allocation.csv", type=['csv'])

# CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒä¸¡æ–¹ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã‚‹å ´åˆã€St.IDã®ãƒªã‚¹ãƒˆã‚’å–å¾—
collection_st_ids = set()
allocation_st_ids = set()

if collection_file is not None:
    collection_df = pd.read_csv(collection_file)
    if 'St.ID' in collection_df.columns:
        collection_st_ids = set(collection_df['St.ID'].dropna().astype(str))
    st.sidebar.success(f"Collection: {len(collection_st_ids)} ä»¶ã®St.IDèª­è¾¼")

if allocation_file is not None:
    allocation_df = pd.read_csv(allocation_file)
    if 'St.ID' in allocation_df.columns:
        allocation_st_ids = set(allocation_df['St.ID'].dropna().astype(str))
    st.sidebar.success(f"Allocation: {len(allocation_st_ids)} ä»¶ã®St.IDèª­è¾¼")

# collectionã‹ã‚‰å›åã—ã¦allocationã«å†é…ç½®ã—ã¦ã„ã‚‹St.IDã®é›†åˆ
matched_st_ids = collection_st_ids & allocation_st_ids
if matched_st_ids:
    st.sidebar.info(f"ğŸ”µ ä¸€è‡´: {len(matched_st_ids)} ä»¶ï¼ˆé’è‰²ã§è¡¨ç¤ºï¼‰")

if apply_cleaning:
    count_before = len(raw_df)
    
    # (A) ä¸€éƒ½ä¸‰çœŒï¼ˆæ±äº¬éƒ½ãƒ»ç¥å¥ˆå·çœŒãƒ»åƒè‘‰çœŒãƒ»åŸ¼ç‰çœŒï¼‰ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ã«é™å®š
    # â€»ä¸€éƒ½ä¸‰çœŒä»¥å¤–ã®ãƒ‡ãƒ¼ã‚¿ã¯ç§»å‹•è·é›¢ã®è¨ˆç®—ç²¾åº¦ã«å•é¡ŒãŒã‚ã‚‹ãŸã‚é™¤å¤–
    target_prefectures = ['åŸ¼ç‰çœŒ', 'åƒè‘‰çœŒ', 'ç¥å¥ˆå·çœŒ', 'æ±äº¬éƒ½']
    processed_df = raw_df.copy()
    
    # å›åå…ƒéƒ½é“åºœçœŒã§ä¸€éƒ½ä¸‰çœŒã®ã¿ã‚’æ®‹ã™
    if 'å›åå…ƒéƒ½é“åºœçœŒ' in processed_df.columns:
        processed_df = processed_df[processed_df['å›åå…ƒéƒ½é“åºœçœŒ'].isin(target_prefectures)]
    
    # å†é…ç½®å…ˆéƒ½é“åºœçœŒã§ã‚‚ä¸€éƒ½ä¸‰çœŒã®ã¿ã‚’æ®‹ã™
    if 'å†é…ç½®å…ˆéƒ½é“åºœçœŒ' in processed_df.columns:
        processed_df = processed_df[processed_df['å†é…ç½®å…ˆéƒ½é“åºœçœŒ'].isin(target_prefectures)]

    # (B) å†é…ç½®ãƒã‚¹ã‚¿ãƒ¼ã«ã‚ã‚‹ST-IDã‚’é™¤å¤–
    processed_df = processed_df[~processed_df['Start Port Id'].isin(exclude_ids)]
    processed_df = processed_df[~processed_df['Return Port Id'].isin(exclude_ids)]

    # (C) å†é…ç½®_FLAGã®ã€ŒåŒã˜STã€ã€ŒNAã€ã‚’é™¤å¤–
    exclude_flags = ['åŒã˜ST', 'NA']
    if 'å†é…ç½®_FLAG' in processed_df.columns:
        processed_df = processed_df[~processed_df['å†é…ç½®_FLAG'].isin(exclude_flags)]
        processed_df = processed_df.dropna(subset=['å†é…ç½®_FLAG'])
    
    count_after = len(processed_df)
    excluded_count = count_before - count_after
    st.sidebar.caption(f"âœ… ä¸€éƒ½ä¸‰çœŒå¤–é™¤å¤–: {excluded_count} ä»¶ / æ®‹ä»¶æ•°: {count_after} ä»¶")

else:
    processed_df = raw_df.copy()


# ---------------------------------------------------------
# 3. ã‚µã‚¤ãƒ‰ãƒãƒ¼æ¤œç´¢æ¡ä»¶ï¼ˆãƒ¦ãƒ¼ã‚¶ãƒ¼æ“ä½œã«ã‚ˆã‚‹çµã‚Šè¾¼ã¿ï¼‰
# ---------------------------------------------------------
st.sidebar.markdown("---")
st.sidebar.header("ğŸ›  æ¤œç´¢æ¡ä»¶ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼")

if processed_df.empty:
    st.error("è¡¨ç¤ºã§ãã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
    st.stop()

# (A) æ—¥ä»˜
if "ä½œæˆæ—¥æ™‚" in processed_df.columns and processed_df["ä½œæˆæ—¥æ™‚"].notnull().any():
    min_date = processed_df["ä½œæˆæ—¥æ™‚"].min().date()
    max_date = processed_df["ä½œæˆæ—¥æ™‚"].max().date()
    date_range = st.sidebar.date_input("æ—¥ä»˜ç¯„å›²", value=(min_date, max_date), min_value=min_date, max_value=max_date)
else:
    st.stop()

# (B) éƒ½é“åºœçœŒ (å†é…ç½®å…ˆ)
all_prefs = processed_df["å†é…ç½®å…ˆéƒ½é“åºœçœŒ"].unique()
selected_prefs = st.sidebar.multiselect("å†é…ç½®å…ˆ éƒ½é“åºœçœŒ", all_prefs, default=all_prefs)

# --- â˜…è¿½åŠ : å¸‚åŒºç”ºæ‘+è¡Œæ”¿åŒºãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ ---

# (C) å›åå…ƒ_å¸‚åŒºç”ºæ‘+è¡Œæ”¿åŒº
if "_filter_å›åå…ƒ_è©³ç´°" in processed_df.columns:
    all_start_cities = sorted(processed_df["_filter_å›åå…ƒ_è©³ç´°"].dropna().unique())
    selected_start_cities = st.sidebar.multiselect("å›åå…ƒ å¸‚åŒºç”ºæ‘ãƒ»è¡Œæ”¿åŒº", all_start_cities, default=all_start_cities)
else:
    selected_start_cities = []
    st.sidebar.caption("â€»å›åå…ƒå¸‚åŒºç”ºæ‘ãƒ‡ãƒ¼ã‚¿ãªã—")

# (D) å†é…ç½®å…ˆ_å¸‚åŒºç”ºæ‘+è¡Œæ”¿åŒº
if "_filter_å†é…ç½®å…ˆ_è©³ç´°" in processed_df.columns:
    all_end_cities = sorted(processed_df["_filter_å†é…ç½®å…ˆ_è©³ç´°"].dropna().unique())
    selected_end_cities = st.sidebar.multiselect("å†é…ç½®å…ˆ å¸‚åŒºç”ºæ‘ãƒ»è¡Œæ”¿åŒº", all_end_cities, default=all_end_cities)
else:
    selected_end_cities = []
    st.sidebar.caption("â€»å†é…ç½®å…ˆ_å¸‚åŒºç”ºæ‘+è¡Œæ”¿åŒºãƒ‡ãƒ¼ã‚¿ãªã—")

# ----------------------------------------

# (E) è·é›¢
max_dist = float(processed_df["å†é…ç½®è·é›¢(km)"].max()) if not processed_df.empty else 100.0
dist_range = st.sidebar.slider("å†é…ç½®è·é›¢ (km)", 0.0, max_dist, (0.0, max_dist))

# (F) è¡¨ç¤ºå
all_names = processed_df["è¡¨ç¤ºå"].unique()
selected_names = st.sidebar.multiselect("è¡¨ç¤ºå (PTä¼æ¥­)", all_names, default=all_names)

# (G) è‡ªè»¢è»Šæ‰€æœ‰ä¼æ¥­
if "è‡ªè»¢è»Šæ‰€æœ‰ä¼æ¥­" in processed_df.columns:
    all_owners = processed_df["è‡ªè»¢è»Šæ‰€æœ‰ä¼æ¥­"].unique()
    selected_owners = st.sidebar.multiselect("è‡ªè»¢è»Šæ‰€æœ‰ä¼æ¥­", all_owners, default=all_owners)
else:
    selected_owners = []

# (H) ãƒã‚¤ã‚¯ã‚«ãƒ†ã‚´ãƒª
if "ãƒã‚¤ã‚¯ã‚«ãƒ†ã‚´ãƒª" in processed_df.columns:
    all_categories = processed_df["ãƒã‚¤ã‚¯ã‚«ãƒ†ã‚´ãƒª"].unique()
    selected_categories = st.sidebar.multiselect("ãƒã‚¤ã‚¯ã‚«ãƒ†ã‚´ãƒª", all_categories, default=all_categories)
else:
    selected_categories = []


# ---------------------------------------------------------
# 4. æœ€çµ‚çµã‚Šè¾¼ã¿å®Ÿè¡Œ
# ---------------------------------------------------------
if len(date_range) != 2:
    st.stop()

# åŸºæœ¬ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
final_df = processed_df[
    (processed_df["ä½œæˆæ—¥æ™‚"].dt.date >= date_range[0]) &
    (processed_df["ä½œæˆæ—¥æ™‚"].dt.date <= date_range[1]) &
    (processed_df["å†é…ç½®å…ˆéƒ½é“åºœçœŒ"].isin(selected_prefs)) &
    (processed_df["å†é…ç½®è·é›¢(km)"] >= dist_range[0]) &
    (processed_df["å†é…ç½®è·é›¢(km)"] <= dist_range[1]) &
    (processed_df["è¡¨ç¤ºå"].isin(selected_names))
]

# â˜…è¿½åŠ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã®é©ç”¨
if "_filter_å›åå…ƒ_è©³ç´°" in processed_df.columns:
    final_df = final_df[final_df["_filter_å›åå…ƒ_è©³ç´°"].isin(selected_start_cities)]

if "_filter_å†é…ç½®å…ˆ_è©³ç´°" in processed_df.columns:
    final_df = final_df[final_df["_filter_å†é…ç½®å…ˆ_è©³ç´°"].isin(selected_end_cities)]

# ãã®ä»–ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
if "è‡ªè»¢è»Šæ‰€æœ‰ä¼æ¥­" in processed_df.columns:
    final_df = final_df[final_df["è‡ªè»¢è»Šæ‰€æœ‰ä¼æ¥­"].isin(selected_owners)]

if "ãƒã‚¤ã‚¯ã‚«ãƒ†ã‚´ãƒª" in processed_df.columns:
    final_df = final_df[final_df["ãƒã‚¤ã‚¯ã‚«ãƒ†ã‚´ãƒª"].isin(selected_categories)]


# ---------------------------------------------------------
# 5. çµæœè¡¨ç¤º
# ---------------------------------------------------------
col1, col2, col3 = st.columns(3)
col1.metric("è©²å½“ä»¶æ•°", f"{len(final_df)} ä»¶")
mean_dist = final_df['å†é…ç½®è·é›¢(km)'].mean() if not final_df.empty else 0
col2.metric("å¹³å‡ç§»å‹•è·é›¢", f"{mean_dist:.2f} km")
max_dist_val = final_df['å†é…ç½®è·é›¢(km)'].max() if not final_df.empty else 0
col3.metric("æœ€å¤§ç§»å‹•è·é›¢", f"{max_dist_val:.2f} km")

tab1, tab2 = st.tabs(["ğŸ—ºï¸ åœ°å›³ã§ç¢ºèª", "ğŸ“‹ ãƒ‡ãƒ¼ã‚¿ä¸€è¦§ï¼†ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰"])

with tab1:
    if not final_df.empty:
        # åœ°å›³ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™
        map_data = final_df.dropna(subset=["lat", "lon"]).copy()
        
        # è‰²åˆ†ã‘åˆ¤å®š: Return Port IdãŒmatched_st_idsã«å«ã¾ã‚Œã‚‹å ´åˆã¯é’ã€ãã‚Œä»¥å¤–ã¯èµ¤
        if matched_st_ids and 'Return Port Id' in map_data.columns:
            map_data['color'] = map_data['Return Port Id'].astype(str).apply(
                lambda x: [0, 0, 255, 200] if x in matched_st_ids else [255, 0, 0, 200]
            )
            st.caption("ğŸ”´ èµ¤: é€šå¸¸ã®å†é…ç½® | ğŸ”µ é’: collectionâ†’allocationã®å†é…ç½®")
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯å…¨ã¦èµ¤
            map_data['color'] = [[255, 0, 0, 200]] * len(map_data)
        
        # pydeckã§åœ°å›³è¡¨ç¤º
        view_state = pdk.ViewState(
            latitude=map_data['lat'].mean(),
            longitude=map_data['lon'].mean(),
            zoom=10,
            pitch=0
        )
        
        layer = pdk.Layer(
            "ScatterplotLayer",
            data=map_data,
            get_position=["lon", "lat"],
            get_color="color",
            get_radius=100,
            pickable=True,
            auto_highlight=True,
        )
        
        tooltip = {
            "html": "<b>è¡¨ç¤ºå:</b> {è¡¨ç¤ºå}<br/>"
                    "<b>å†é…ç½®å…ˆ:</b> {å†é…ç½®å…ˆéƒ½é“åºœçœŒ}<br/>"
                    "<b>è·é›¢:</b> {å†é…ç½®è·é›¢(km)} km<br/>"
                    "<b>St.ID:</b> {Start Port Id} â†’ {Return Port Id}",
            "style": {"backgroundColor": "steelblue", "color": "white"}
        }
        
        deck = pdk.Deck(
            layers=[layer],
            initial_view_state=view_state,
            tooltip=tooltip,
            map_style="mapbox://styles/mapbox/light-v9"
        )
        
        st.pydeck_chart(deck)
    else:
        st.warning("æ¡ä»¶ã«ä¸€è‡´ã™ã‚‹ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")

with tab2:
    if not final_df.empty:
        # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨ã«ä¸€æ™‚åˆ—ï¼ˆ_filter_...ï¼‰ã¯å‰Šé™¤ã—ã¦ã‚‚è‰¯ã„ã§ã™ãŒã€ç¢ºèªç”¨ã«ã‚ãˆã¦æ®‹ã—ã¦ã„ã¾ã™
        csv = final_df.to_csv(index=False).encode('utf-8_sig')
        st.download_button(
            label="ğŸ“¥ CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
            data=csv,
            file_name="filtered_reallocation_data.csv",
            mime="text/csv",
        )
    st.dataframe(final_df, use_container_width=True)